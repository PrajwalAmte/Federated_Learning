{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f5ad46-cb40-4f7e-b0ab-c2d11c7b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79e00bc-e4cc-4547-a94d-0c2126b2430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "train_df = pd.read_csv(\"Dataset/mitbih_train.csv\", header=None)\n",
    "test_df = pd.read_csv(\"Dataset/mitbih_test.csv\", header=None)\n",
    "\n",
    "# Binary classification: Convert class labels to 0 and 1\n",
    "train_df[187] = train_df[187].apply(lambda x: 0 if x == 0 else 1)\n",
    "test_df[187] = test_df[187].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "y_train = train_df[187].values\n",
    "X_test = test_df.iloc[:, :-1].values\n",
    "y_test = test_df[187].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88707f93-4474-4fcd-884a-5e15be940437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6    \\\n",
      "0      0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
      "1      0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
      "2      1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
      "3      0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
      "4      0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "87549  0.807018  0.494737  0.536842  0.529825  0.491228  0.484211  0.456140   \n",
      "87550  0.718333  0.605000  0.486667  0.361667  0.231667  0.120000  0.051667   \n",
      "87551  0.906122  0.624490  0.595918  0.575510  0.530612  0.481633  0.444898   \n",
      "87552  0.858228  0.645570  0.845570  0.248101  0.167089  0.131646  0.121519   \n",
      "87553  0.901506  0.845886  0.800695  0.748552  0.687138  0.599073  0.512167   \n",
      "\n",
      "            7         8         9    ...  178  179  180  181  182  183  184  \\\n",
      "0      0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1      0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2      0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3      0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4      0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "87549  0.396491  0.284211  0.136842  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "87550  0.001667  0.000000  0.013333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "87551  0.387755  0.322449  0.191837  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "87552  0.121519  0.118987  0.103797  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "87553  0.427578  0.395133  0.402086  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       185  186  187  \n",
      "0      0.0  0.0    0  \n",
      "1      0.0  0.0    0  \n",
      "2      0.0  0.0    0  \n",
      "3      0.0  0.0    0  \n",
      "4      0.0  0.0    0  \n",
      "...    ...  ...  ...  \n",
      "87549  0.0  0.0    1  \n",
      "87550  0.0  0.0    1  \n",
      "87551  0.0  0.0    1  \n",
      "87552  0.0  0.0    1  \n",
      "87553  0.0  0.0    1  \n",
      "\n",
      "[87554 rows x 188 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00fce57-ecc6-40ed-8b35-e374d6f11254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and convert to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Adding channel dimension\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6a85de-143d-41dc-aaa4-62184e52da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate hospitals by splitting the training data\n",
    "hospital_1_size = len(train_dataset) // 3\n",
    "hospital_2_size = len(train_dataset) // 3\n",
    "hospital_3_size = len(train_dataset) - hospital_1_size - hospital_2_size\n",
    "\n",
    "hospital_1_data, hospital_2_data, hospital_3_data = random_split(\n",
    "    train_dataset, [hospital_1_size, hospital_2_size, hospital_3_size]\n",
    ")\n",
    "\n",
    "hospital_1_loader = DataLoader(hospital_1_data, batch_size=32, shuffle=True)\n",
    "hospital_2_loader = DataLoader(hospital_2_data, batch_size=32, shuffle=True)\n",
    "hospital_3_loader = DataLoader(hospital_3_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c0b3801-a76b-4207-9431-98d04ffcadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # The output size after convolutions and pooling\n",
    "        # Input size = 187\n",
    "        # After conv1: (187 + 2*1 - 3) / 1 + 1 = 187\n",
    "        # After pool: 187 / 2 = 93\n",
    "        # After conv2: (93 + 2*1 - 3) / 1 + 1 = 93\n",
    "        # After pool: 93 / 2 = 46 (rounded down)\n",
    "        flattened_size = 64 * 46  # 64 channels * 46 length\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Convolution + Pooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # Convolution + Pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))  # Fully connected layer 1\n",
    "        x = self.fc2(x)  # Fully connected layer 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ea095a-f798-4750-a1db-94c615e0a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on a single hospital\n",
    "def train_on_hospital(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09d8d27c-e4e2-4831-9375-0bd162f01eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated training\n",
    "def federated_training(model, hospitals, epochs=5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        for i, hospital_loader in enumerate(hospitals, 1):\n",
    "            print(f\"Training on Hospital {i}\")\n",
    "            train_on_hospital(model, hospital_loader, optimizer, criterion)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30387a0d-4889-4715-8ad7-1d50be5f4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c94d0d07-27a9-404e-9e34-fa5e2240d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training on Hospital 1\n",
      "Training on Hospital 2\n",
      "Training on Hospital 3\n",
      "Epoch 2\n",
      "Training on Hospital 1\n",
      "Training on Hospital 2\n",
      "Training on Hospital 3\n",
      "Epoch 3\n",
      "Training on Hospital 1\n",
      "Training on Hospital 2\n",
      "Training on Hospital 3\n",
      "Epoch 4\n",
      "Training on Hospital 1\n",
      "Training on Hospital 2\n",
      "Training on Hospital 3\n",
      "Epoch 5\n",
      "Training on Hospital 1\n",
      "Training on Hospital 2\n",
      "Training on Hospital 3\n"
     ]
    }
   ],
   "source": [
    "# Train the model using federated learning\n",
    "hospitals = [hospital_1_loader, hospital_2_loader, hospital_3_loader]\n",
    "federated_training(model, hospitals, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df1a51d9-46ee-4345-9cec-fc6fddab6a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.00840489676594%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the global model\n",
    "accuracy = evaluate_model(model, test_loader)\n",
    "print(f\"Accuracy on test set: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de643da-1b4b-4259-bfa8-df5b701f9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the global model\n",
    "torch.save(model.state_dict(), \"federated_global_model.pth\")\n",
    "print(\"Federated Global Model saved as 'federated_global_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
